{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch | 深入剖析torch.nn.Module方法及源码\n",
    "\n",
    "torch.nn是一个专门为神经网络设计的模块化接口，包含卷积、池化、线性等计算，以及其他如loss等，可以将torch.nn中的每一个模块看做神经网络中的每一层。\n",
    "\n",
    "torch.nn.Module是网络模型的一个基类，大部分自定义的子模型（卷积、池化甚至整个网络）是这个基类的子类。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 一、`class torch.nn.Parameter`\n",
    "\n",
    "功能：`torch.nn.Parameter`是继承至`torch.tensor`的子类，Parameter类型会自动被认为是module的可训练参数，即加入`.parameter()`迭代器中。\n",
    "\n",
    "exp: `torch.nn.Parameter(torch.tensor[3.14159],requore_grad=True)`\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 二、`class torch.nn.Module`\n",
    "\n",
    "### 2.1 构建模型\n",
    "\n",
    "首先我们看看如何定义一个Module："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 20, 5)\n",
    "        self.conv2 = nn.Conv2d(20, 20, 5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        return F.relu(self.conv2(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Module类包含48个方法，下面我们来看一下这些方法如何使用。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 子模型操作"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> register_module()\n",
    "\n",
    "add_module方法的封装，用于将新的`name:module`键值对加入module中。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> add_module(name, module)\n",
    "\n",
    "将子模块添加到当前模块。example："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model(\n",
      "  (conv1): Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "\n",
    "        # 下面是两种等价方式\n",
    "        self.conv1 = nn.Conv2d(1, 20, 5)\n",
    "        self.add_module(\"conv2\", nn.Conv2d(1, 20, 5))\n",
    "\n",
    "model = Model()\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 访问子模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.conv1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> children()：\n",
    "\n",
    "返回网络模型里的组成元素的迭代器。类似`modules()`方法。二者对比可参考：[https://blog.csdn.net/u013066730/article/details/94600978](https://blog.csdn.net/u013066730/article/details/94600978)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))\n"
     ]
    }
   ],
   "source": [
    "for i in model.children():\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> named_children()\n",
    "\n",
    "返回直接子模块的迭代器，产生模块的名称以及模块本身。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1 Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "conv2 Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))\n"
     ]
    }
   ],
   "source": [
    "for name, module in model.named_children():\n",
    "    print(name,module)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> `modules()`\n",
    "\n",
    "返回当前模型所有模型的迭代器，重复的模型只被返回一次。与`children()`方法不同，`modules()`方法还会返回当前模型module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=2, out_features=2, bias=True)\n",
      "  (1): Linear(in_features=2, out_features=2, bias=True)\n",
      "  (2): ReLU()\n",
      "  (3): Sequential(\n",
      "    (0): Linear(in_features=2, out_features=2, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      ")\n",
      "Linear(in_features=2, out_features=2, bias=True)\n",
      "Linear(in_features=2, out_features=2, bias=True)\n",
      "ReLU()\n",
      "Sequential(\n",
      "  (0): Linear(in_features=2, out_features=2, bias=True)\n",
      "  (1): ReLU()\n",
      ")\n",
      "Linear(in_features=2, out_features=2, bias=True)\n",
      "ReLU()\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "net = nn.Sequential(nn.Linear(2, 2), \n",
    "                    nn.Linear(2, 2),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Sequential(nn.Linear(2, 2),\n",
    "                                    nn.ReLU())\n",
    "                    )\n",
    "for module in net.modules():\n",
    "    print(module)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> named_modules\n",
    "\n",
    "返回网络中所有模块的迭代器，产生模块的名称以及模块本身。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " GaussianModel()\n"
     ]
    }
   ],
   "source": [
    "for name, module in model.named_modules():\n",
    "    print(name, module)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> get_submodule(target: str) -> 'Module'\n",
    "\n",
    "从Module中获取子module，example："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 模型参数（parameter）与缓冲区（buffer）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> register_parameter(self, name: str, param: Optional[Parameter])\n",
    "\n",
    "用于在当前模块中添加一个parameter变量，其中参数param是一个Parameter类型（继承至tensor类型，nn.parameter.Parameter）。\n",
    "\n",
    "Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class GaussianModel(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(GaussianModel, self).__init__()\n",
    "\n",
    "        self.register_parameter('mean', nn.Parameter(torch.zeros(1),\n",
    "                                                     requires_grad=True))\n",
    "        \n",
    "        self.pdf = torch.distributions.Normal(self.state_dict()['mean'],\n",
    "                                              torch.tensor([1.0]))\n",
    "    def forward(self, x):\n",
    "        return -self.pdf.log_prob(x)\n",
    "\n",
    "model = GaussianModel()\n",
    "for name, param in model.named_parameters():\n",
    "    print(name,param.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> parameters(recurse=True)\n",
    "\n",
    "返回模型参数的迭代器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    print(type(param), param.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> named_parameters(prefix='', recurse=True)\n",
    "\n",
    "返回模块参数的迭代器，产生参数的名称以及参数本身。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.weight torch.Size([2, 2])\n",
      "0.bias torch.Size([2])\n",
      "1.weight torch.Size([2, 2])\n",
      "1.bias torch.Size([2])\n",
      "3.0.weight torch.Size([2, 2])\n",
      "3.0.bias torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "for name, param in net.named_parameters():\n",
    "    print(name,param.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> get_parameter(target: str)\n",
    "\n",
    "根据参数名得到参数，exp："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.1466, -0.1264],\n",
       "        [ 0.2812,  0.1436]], requires_grad=True)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.get_parameter('1.weight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> buffers(recurse=True)\n",
    "\n",
    "模型中需要保存下来的参数包括两种：\n",
    "\n",
    "+ 一种是反向传播需要更新：parameter，可以通过parameter()返回\n",
    "+ 一种是反向传播不需要更新的：buffer，可以通过buffer()返回"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> named_buffers(prefix='', recurse=True)\n",
    "\n",
    "返回module buffers' name的迭代器，example： "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, buf in net.named_buffers():\n",
    "    print(buf.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> register_buffer(name: str, tensor: Optional[Tensor], persistent: bool = True)\n",
    "\n",
    "在当前模块中添加一个buffer变量，例如，现在需要手写一个BatchNorm，那么其`running_mean`并不是一个parameter，这就需要用下述方式注册一个buffer：\n",
    "\n",
    "```python\n",
    "class BatchNorm(nn.Module):\n",
    "    def __init__(self,..):\n",
    "        self.register_buffer('running_mean',torch.zeros(num_features))\n",
    "        self.register_buffer('running_variance',torch.ones(num_features))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> get_buffer(target: str)\n",
    "\n",
    "根据buffer名得到buffer值，用法同get_parameter。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 数据格式及转换"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> float() / double() / half() / bfloat16() \n",
    "\n",
    "将所有的parameters和buffers转化为指定的数据类型。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> type(dst_type)\n",
    "\n",
    "将所有的parameters和buffers转化为目标数据类型。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 模型移动"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> to_empty()\n",
    "\n",
    "把模型parameter和buffers移动到指定device上（不保存其具体数值）。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> cpu() / cuda() / xpu(）\n",
    "\n",
    "将模型的parameters和buffers移动到CPU/GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 模型模式调整"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> train(mode=True)\n",
    "将该模块设置为train训练模式。默认值：True。\n",
    "\n",
    "> eval()\n",
    "\n",
    "将module设置为验证模式，会影响一些特定modules，如：Dropout，BatchNorm等"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 其他\n",
    "\n",
    "> zero_grad(set_to_none=False)\n",
    "\n",
    "将所有模型参数的梯度设置为零。set_to_none=True会让内存分配器来处理梯度，而不是主动将它们设置为0，这样会适度加速。\n",
    "\n",
    "> forward(*input)\n",
    "\n",
    "方法定义了神经网络每次调用时都需要执行的前向传播计算，所有的子类都必须要重写这个方法。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> apply(fn)\n",
    "\n",
    "+ 递归地将函数应用于所有子模块。\n",
    "+ apply方法可以用于任何submodule（通过.children()或者self.获取到的）\n",
    "+ 常用来初始化模型参数（同torch.nn.init）\n",
    "\n",
    "example:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=2, out_features=2, bias=True)\n",
      "Parameter containing:\n",
      "tensor([[1., 1.],\n",
      "        [1., 1.]], requires_grad=True)\n",
      "Linear(in_features=2, out_features=2, bias=True)\n",
      "Parameter containing:\n",
      "tensor([[1., 1.],\n",
      "        [1., 1.]], requires_grad=True)\n",
      "ReLU()\n",
      "Linear(in_features=2, out_features=2, bias=True)\n",
      "Parameter containing:\n",
      "tensor([[1., 1.],\n",
      "        [1., 1.]], requires_grad=True)\n",
      "ReLU()\n",
      "Sequential(\n",
      "  (0): Linear(in_features=2, out_features=2, bias=True)\n",
      "  (1): ReLU()\n",
      ")\n",
      "Sequential(\n",
      "  (0): Linear(in_features=2, out_features=2, bias=True)\n",
      "  (1): Linear(in_features=2, out_features=2, bias=True)\n",
      "  (2): ReLU()\n",
      "  (3): Sequential(\n",
      "    (0): Linear(in_features=2, out_features=2, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=2, out_features=2, bias=True)\n",
       "  (1): Linear(in_features=2, out_features=2, bias=True)\n",
       "  (2): ReLU()\n",
       "  (3): Sequential(\n",
       "    (0): Linear(in_features=2, out_features=2, bias=True)\n",
       "    (1): ReLU()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "@torch.no_grad()  # 不计算梯度，不反向传播\n",
    "def init_weights(m):\n",
    "    print(m)\n",
    "    if type(m) == nn.Linear:\n",
    "        m.weight.fill_(1.0)\n",
    "        print(m.weight)\n",
    "net = nn.Sequential(nn.Linear(2, 2), nn.Linear(2, 2),nn.ReLU(),nn.Sequential(nn.Linear(2, 2),nn.ReLU()))\n",
    "net.apply(init_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> load_state_dict(state_dict, strict=True)\n",
    "\n",
    "将 state_dict 中的参数(parameters)和缓冲区(buffers)复制到此模块及其子模块中。如果 strict 为 True，则 state_dict 的键必须与该模块的 state_dict() 函数返回的键完全匹配。\n",
    "\n",
    "> state_dict()\n",
    "\n",
    "返回包含模块整个状态的字典。 包括参数和持久缓冲区（例如运行平均值）。键是对应的参数和缓冲区名称。不包括设置为 None 的参数和缓冲区。常用于保存模型参数。\n",
    "\n",
    "保存模型例子：\n",
    "\n",
    "```python\n",
    "# Additional information\n",
    "EPOCH = 5\n",
    "PATH = \"model.pt\"\n",
    "LOSS = 0.4\n",
    "\n",
    "torch.save({\n",
    "            'epoch': EPOCH,\n",
    "            'model_state_dict': net.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': LOSS,\n",
    "            }, PATH)\n",
    "```\n",
    "\n",
    "加载模型例子：\n",
    "```python\n",
    "model = Net()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "checkpoint = torch.load(PATH)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "epoch = checkpoint['epoch']\n",
    "loss = checkpoint['loss']\n",
    "\n",
    "model.eval()\n",
    "# - or -\n",
    "model.train()\n",
    "```\n",
    "更多详情参考：[https://pytorch.org/tutorials/recipes/recipes/saving_and_loading_a_general_checkpoint.html](https://pytorch.org/tutorials/recipes/recipes/saving_and_loading_a_general_checkpoint.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> _apply(fn)\n",
    "\n",
    "+ 对所有的module、parameter、buffer都进行一个fn\n",
    "\n",
    "Example：.cpu / .cuda()源码\n",
    "\n",
    "```python\n",
    "class Module:\n",
    "    def cuda(self: T, device: Optional[Union[int, device]] = None) -> T:\n",
    "        r\"\"\"Moves all model parameters and buffers to the GPU.\n",
    "\n",
    "        This also makes associated parameters and buffers different objects. So\n",
    "        it should be called before constructing optimizer if the module will\n",
    "        live on GPU while being optimized.\n",
    "\n",
    "        .. note::\n",
    "            This method modifies the module in-place.\n",
    "\n",
    "        Args:\n",
    "            device (int, optional): if specified, all parameters will be\n",
    "                copied to that device\n",
    "\n",
    "        Returns:\n",
    "            Module: self\n",
    "        \"\"\"\n",
    "        return self._apply(lambda t: t.cuda(device))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 三、hook方法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name '_log_api_usage_once' from 'torchvision.utils' (/Users/liujiyao/miniforge3/envs/torchcpu/lib/python3.8/site-packages/torchvision/utils.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m/Users/liujiyao/Documents/DL-note/torch_source_code/torch.nn.Module/Module.ipynb Cell 50\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/liujiyao/Documents/DL-note/torch_source_code/torch.nn.Module/Module.ipynb#ch0000056?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtimm\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/liujiyao/Documents/DL-note/torch_source_code/torch.nn.Module/Module.ipynb#ch0000056?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/torchcpu/lib/python3.8/site-packages/timm/__init__.py:2\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mversion\u001b[39;00m \u001b[39mimport\u001b[39;00m __version__\n\u001b[0;32m----> 2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m \u001b[39mimport\u001b[39;00m create_model, list_models, is_model, list_modules, model_entrypoint, \\\n\u001b[1;32m      3\u001b[0m     is_scriptable, is_exportable, set_scriptable, set_exportable, has_pretrained_cfg_key, is_pretrained_cfg_key, \\\n\u001b[1;32m      4\u001b[0m     get_pretrained_cfg_value, is_model_pretrained\n",
      "File \u001b[0;32m~/miniforge3/envs/torchcpu/lib/python3.8/site-packages/timm/models/__init__.py:1\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mbeit\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mbyoanet\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mbyobnet\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n",
      "File \u001b[0;32m~/miniforge3/envs/torchcpu/lib/python3.8/site-packages/timm/models/beit.py:33\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mlayers\u001b[39;00m \u001b[39mimport\u001b[39;00m PatchEmbed, Mlp, DropPath, trunc_normal_\n\u001b[1;32m     32\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mregistry\u001b[39;00m \u001b[39mimport\u001b[39;00m register_model\n\u001b[0;32m---> 33\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mvision_transformer\u001b[39;00m \u001b[39mimport\u001b[39;00m checkpoint_filter_fn\n\u001b[1;32m     36\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_cfg\u001b[39m(url\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     37\u001b[0m     \u001b[39mreturn\u001b[39;00m {\n\u001b[1;32m     38\u001b[0m         \u001b[39m'\u001b[39m\u001b[39murl\u001b[39m\u001b[39m'\u001b[39m: url,\n\u001b[1;32m     39\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mnum_classes\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m1000\u001b[39m, \u001b[39m'\u001b[39m\u001b[39minput_size\u001b[39m\u001b[39m'\u001b[39m: (\u001b[39m3\u001b[39m, \u001b[39m224\u001b[39m, \u001b[39m224\u001b[39m), \u001b[39m'\u001b[39m\u001b[39mpool_size\u001b[39m\u001b[39m'\u001b[39m: \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[1;32m     44\u001b[0m     }\n",
      "File \u001b[0;32m~/miniforge3/envs/torchcpu/lib/python3.8/site-packages/timm/models/vision_transformer.py:33\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mnn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfunctional\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mF\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcheckpoint\u001b[39;00m\n\u001b[0;32m---> 33\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtimm\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m \u001b[39mimport\u001b[39;00m IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD, IMAGENET_INCEPTION_MEAN, IMAGENET_INCEPTION_STD\n\u001b[1;32m     34\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mhelpers\u001b[39;00m \u001b[39mimport\u001b[39;00m build_model_with_cfg, resolve_pretrained_cfg, named_apply, adapt_input_conv, checkpoint_seq\n\u001b[1;32m     35\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mlayers\u001b[39;00m \u001b[39mimport\u001b[39;00m PatchEmbed, Mlp, DropPath, trunc_normal_, lecun_normal_\n",
      "File \u001b[0;32m~/miniforge3/envs/torchcpu/lib/python3.8/site-packages/timm/data/__init__.py:5\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mconfig\u001b[39;00m \u001b[39mimport\u001b[39;00m resolve_data_config\n\u001b[1;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mconstants\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[0;32m----> 5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mdataset\u001b[39;00m \u001b[39mimport\u001b[39;00m ImageDataset, IterableImageDataset, AugMixDataset\n\u001b[1;32m      6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mdataset_factory\u001b[39;00m \u001b[39mimport\u001b[39;00m create_dataset\n\u001b[1;32m      7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mloader\u001b[39;00m \u001b[39mimport\u001b[39;00m create_loader\n",
      "File \u001b[0;32m~/miniforge3/envs/torchcpu/lib/python3.8/site-packages/timm/data/dataset.py:12\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mlogging\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mPIL\u001b[39;00m \u001b[39mimport\u001b[39;00m Image\n\u001b[0;32m---> 12\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mparsers\u001b[39;00m \u001b[39mimport\u001b[39;00m create_parser\n\u001b[1;32m     14\u001b[0m _logger \u001b[39m=\u001b[39m logging\u001b[39m.\u001b[39mgetLogger(\u001b[39m__name__\u001b[39m)\n\u001b[1;32m     17\u001b[0m _ERROR_RETRY \u001b[39m=\u001b[39m \u001b[39m50\u001b[39m\n",
      "File \u001b[0;32m~/miniforge3/envs/torchcpu/lib/python3.8/site-packages/timm/data/parsers/__init__.py:1\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mparser_factory\u001b[39;00m \u001b[39mimport\u001b[39;00m create_parser\n\u001b[1;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mimg_extensions\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n",
      "File \u001b[0;32m~/miniforge3/envs/torchcpu/lib/python3.8/site-packages/timm/data/parsers/parser_factory.py:3\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mos\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mparser_image_folder\u001b[39;00m \u001b[39mimport\u001b[39;00m ParserImageFolder\n\u001b[1;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mparser_image_in_tar\u001b[39;00m \u001b[39mimport\u001b[39;00m ParserImageInTar\n\u001b[1;32m      7\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate_parser\u001b[39m(name, root, split\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n",
      "File \u001b[0;32m~/miniforge3/envs/torchcpu/lib/python3.8/site-packages/timm/data/parsers/parser_image_folder.py:11\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mos\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtyping\u001b[39;00m \u001b[39mimport\u001b[39;00m Dict, List, Optional, Set, Tuple, Union\n\u001b[0;32m---> 11\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtimm\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmisc\u001b[39;00m \u001b[39mimport\u001b[39;00m natural_key\n\u001b[1;32m     13\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mclass_map\u001b[39;00m \u001b[39mimport\u001b[39;00m load_class_map\n\u001b[1;32m     14\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mimg_extensions\u001b[39;00m \u001b[39mimport\u001b[39;00m get_img_extensions\n",
      "File \u001b[0;32m~/miniforge3/envs/torchcpu/lib/python3.8/site-packages/timm/utils/__init__.py:2\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39magc\u001b[39;00m \u001b[39mimport\u001b[39;00m adaptive_clip_grad\n\u001b[0;32m----> 2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mcheckpoint_saver\u001b[39;00m \u001b[39mimport\u001b[39;00m CheckpointSaver\n\u001b[1;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mclip_grad\u001b[39;00m \u001b[39mimport\u001b[39;00m dispatch_clip_grad\n\u001b[1;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mcuda\u001b[39;00m \u001b[39mimport\u001b[39;00m ApexScaler, NativeScaler\n",
      "File \u001b[0;32m~/miniforge3/envs/torchcpu/lib/python3.8/site-packages/timm/utils/checkpoint_saver.py:15\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mlogging\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mmodel\u001b[39;00m \u001b[39mimport\u001b[39;00m unwrap_model, get_state_dict\n\u001b[1;32m     18\u001b[0m _logger \u001b[39m=\u001b[39m logging\u001b[39m.\u001b[39mgetLogger(\u001b[39m__name__\u001b[39m)\n\u001b[1;32m     21\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mCheckpointSaver\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniforge3/envs/torchcpu/lib/python3.8/site-packages/timm/utils/model.py:8\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mfnmatch\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorchvision\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mops\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmisc\u001b[39;00m \u001b[39mimport\u001b[39;00m FrozenBatchNorm2d\n\u001b[1;32m     10\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mmodel_ema\u001b[39;00m \u001b[39mimport\u001b[39;00m ModelEma\n\u001b[1;32m     13\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39munwrap_model\u001b[39m(model):\n",
      "File \u001b[0;32m~/miniforge3/envs/torchcpu/lib/python3.8/site-packages/torchvision/ops/__init__.py:2\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_register_onnx_ops\u001b[39;00m \u001b[39mimport\u001b[39;00m _register_custom_op\n\u001b[0;32m----> 2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mboxes\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m      3\u001b[0m     nms,\n\u001b[1;32m      4\u001b[0m     batched_nms,\n\u001b[1;32m      5\u001b[0m     remove_small_boxes,\n\u001b[1;32m      6\u001b[0m     clip_boxes_to_image,\n\u001b[1;32m      7\u001b[0m     box_area,\n\u001b[1;32m      8\u001b[0m     box_iou,\n\u001b[1;32m      9\u001b[0m     generalized_box_iou,\n\u001b[1;32m     10\u001b[0m     masks_to_boxes,\n\u001b[1;32m     11\u001b[0m )\n\u001b[1;32m     12\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mboxes\u001b[39;00m \u001b[39mimport\u001b[39;00m box_convert\n\u001b[1;32m     13\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mdeform_conv\u001b[39;00m \u001b[39mimport\u001b[39;00m deform_conv2d, DeformConv2d\n",
      "File \u001b[0;32m~/miniforge3/envs/torchcpu/lib/python3.8/site-packages/torchvision/ops/boxes.py:8\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m \u001b[39mimport\u001b[39;00m Tensor\n\u001b[1;32m      6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorchvision\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mextension\u001b[39;00m \u001b[39mimport\u001b[39;00m _assert_has_ops\n\u001b[0;32m----> 8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m _log_api_usage_once\n\u001b[1;32m      9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_box_convert\u001b[39;00m \u001b[39mimport\u001b[39;00m _box_cxcywh_to_xyxy, _box_xyxy_to_cxcywh, _box_xywh_to_xyxy, _box_xyxy_to_xywh\n\u001b[1;32m     12\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mnms\u001b[39m(boxes: Tensor, scores: Tensor, iou_threshold: \u001b[39mfloat\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name '_log_api_usage_once' from 'torchvision.utils' (/Users/liujiyao/miniforge3/envs/torchcpu/lib/python3.8/site-packages/torchvision/utils.py)"
     ]
    }
   ],
   "source": [
    "import timm\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('torchcpu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aa491c18d0be0c4e8a787577469a16b94dd30119a7d01c99fcb9d2f4862fba4b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
